{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQyfa3akfIEZ"
      },
      "source": [
        "**Level**: Intermediate\n",
        "\n",
        "**Time to complete**: 20 minutes\n",
        "\n",
        "**Prerequisites**: Prepare the Colab environment (see links below).\n",
        "\n",
        "**Nodes Used**: InMemoryDocumentStore, MultiModalRetriever\n",
        "\n",
        "**Goal**: After completing this tutorial, you will have learned about the MultiModalRetriever, and built a simple retrieval pipeline that search relevant images given a text query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzn2uA1Be1Km"
      },
      "source": [
        "## Preparing the Colab Environment\n",
        "\n",
        "- [Enable GPU Runtime in GPU](https://docs.haystack.deepset.ai/v5.2-unstable/docs/enable-gpu-runtime-in-colab)\n",
        "- [Check if GPU is Enabled](https://docs.haystack.deepset.ai/v5.2-unstable/docs/check-if-gpu-is-enabled)\n",
        "- [Set logging level to INFO](https://docs.haystack.deepset.ai/v5.2-unstable/docs/set-the-logging-level)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hl92D-ZlycPh"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "pip install --upgrade pip\n",
        "pip install farm-haystack[colab]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s62Z-1xL40vp"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(level=logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkVAG7FdXsEU"
      },
      "source": [
        "# Initializing the DocumentStore\n",
        "\n",
        "A DocumentStore contains Documents, which in this case are references to the images that Haystack will compare with your query. Here we are using the InMemoryDocumentStore since it requires no external dependencies. To learn more about the DocumentStore and the different types of external databases that we support, see [DocumentStore](https://docs.haystack.deepset.ai/docs/document_store)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dK86aFlSYQXv"
      },
      "outputs": [],
      "source": [
        "from haystack.document_stores import InMemoryDocumentStore\n",
        "\n",
        "document_store = InMemoryDocumentStore(embedding_dim=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGNwBu0yYcDq"
      },
      "source": [
        "# Downloading data\n",
        "\n",
        "Download 18 sample images of different animals from . You can find them in data/tutorial19/spirit-animals/ as a set of .jpg files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yk_Prp3yYUa"
      },
      "outputs": [],
      "source": [
        "from haystack.utils import fetch_archive_from_http\n",
        "\n",
        "doc_dir = \"data/tutorial19\"\n",
        "\n",
        "fetch_archive_from_http(\n",
        "    url=\"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/spirit-animals.zip\",\n",
        "    output_dir=doc_dir\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOJC6m8cqzCl"
      },
      "source": [
        "Add the images you just downloaded into Haystack Document objects and write them into the DocumentStore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pdDsSVp40vr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from haystack import Document\n",
        "\n",
        "images = [\n",
        "    Document(content=f\"./{doc_dir}/spirit-animals/{filename}\", content_type=\"image\")\n",
        "    for filename in os.listdir(f\"./{doc_dir}/spirit-animals/\")\n",
        "]\n",
        "\n",
        "document_store.write_documents(images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfmeRIE9wz9o"
      },
      "source": [
        "# Initializing the Retriever\n",
        "\n",
        "Retrievers sift through all the images and return only those that are relevant based on the input query. Here we are using the OpenAI CLIP model to embed images. For more details on supported modalities, see [MultiModalRetriever](https://docs.haystack.deepset.ai/docs/retriever#multimodal-retrieval)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuL1mtq6qx0d"
      },
      "outputs": [],
      "source": [
        "from haystack.nodes.retriever.multimodal import MultiModalRetriever\n",
        "\n",
        "retriever_text_to_image = MultiModalRetriever(\n",
        "    document_store=document_store,\n",
        "    query_embedding_model = \"sentence-transformers/clip-ViT-B-32\",\n",
        "    query_type=\"text\",\n",
        "    document_embedding_models = {\"image\": \"sentence-transformers/clip-ViT-B-32\"} #, \"text\": \"sentence-transformers/clip-ViT-B-32\"},\n",
        ")\n",
        "\n",
        "document_store.update_embeddings(retriever=retriever_text_to_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMNYvDjd9sqY"
      },
      "source": [
        "# Creating the MultiModal search Pipeline\n",
        "\n",
        "We use a generic Pipeline that uses MultiModalRetriever as node and creates a search pipeline. This search pipeline allows us to query the image database with text queries and returns most relevant images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-a6ltABP40vs"
      },
      "outputs": [],
      "source": [
        "from haystack import Pipeline\n",
        "\n",
        "pipeline = Pipeline()\n",
        "pipeline.add_node(component=retriever_text_to_image, name=\"retriever_text_to_image\", \n",
        "                  inputs=[\"Query\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSjizWzAF6T9"
      },
      "source": [
        "# Searching through the images\n",
        "\n",
        "Use the pipeline `run()` method to query the images in the document store. The query argument is where you type your text query. Additionally, you can set the number of images you want the MultiModalRetriever to return using the `top-k` parameter. To learn more about setting arguments, see [Pipeline Arguments](https://docs.haystack.deepset.ai/docs/pipelines#arguments)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRH5UbIdF7CW"
      },
      "outputs": [],
      "source": [
        "results = pipeline.run(query=\"Animal who lives in the water\",\n",
        "                       params={\"retriever_text_to_image\": {\"top_k\": 3}})\n",
        "\n",
        "results = sorted(results[\"documents\"], key=lambda d: d.score, reverse=True)\n",
        "\n",
        "for doc in results:\n",
        "    print(doc.score, doc.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoEt2cHHTdIZ"
      },
      "source": [
        "Here are some more query strings you could try out:\n",
        "\n",
        "1.   King of the Jungle\n",
        "2.   Fastest animal\n",
        "3.   Bird who can see clearly even in the dark\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBukVUVVU0if"
      },
      "source": [
        "You can also vizualize these images with their score easily with below code.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSjZHuv68Hut"
      },
      "outputs": [],
      "source": [
        "from io import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageOps\n",
        "from IPython.display import display, Image as IPImage\n",
        "\n",
        "def display_img_array(ima, score):\n",
        "    im = Image.open(ima)\n",
        "    img_with_border = ImageOps.expand(im ,border=20, fill='white')\n",
        "\n",
        "    # Add Text to an image\n",
        "    img = ImageDraw.Draw(img_with_border)\n",
        "    img.text((20, 0), f\"Score: {score},    Path: {ima}\", fill=(0, 0, 0))\n",
        "\n",
        "    bio = BytesIO()\n",
        "    img_with_border.save(bio, format='png')\n",
        "    display(IPImage(bio.getvalue(), format='png'))\n",
        "\n",
        "images_array = [doc.content for doc in results]\n",
        "scores = [doc.score for doc in results]\n",
        "for ima, score in zip(images_array, scores):\n",
        "    display_img_array(ima, score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RyMcCI2_yHf"
      },
      "source": [
        "## About us\n",
        "\n",
        "This [Haystack](https://github.com/deepset-ai/haystack/) notebook was made with love by [deepset](https://deepset.ai/) in Berlin, Germany\n",
        "\n",
        "We bring NLP to the industry via open source!  \n",
        "Our focus: Industry specific language models & large scale QA systems.  \n",
        "  \n",
        "Some of our other work: \n",
        "- [German BERT](https://deepset.ai/german-bert)\n",
        "- [GermanQuAD and GermanDPR](https://deepset.ai/germanquad)\n",
        "\n",
        "Get in touch:\n",
        "[Twitter](https://twitter.com/deepset_ai) | [LinkedIn](https://www.linkedin.com/company/deepset-ai/) | [Discord](https://haystack.deepset.ai/community/join) | [GitHub Discussions](https://github.com/deepset-ai/haystack/discussions) | [Website](https://deepset.ai)\n",
        "\n",
        "By the way: [we're hiring!](https://www.deepset.ai/jobs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
