{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVBtOVlNJ51C"
   },
   "source": [
    "# Tutorial: Generating Structured Output with Loop-Based Auto-Correction\n",
    "\n",
    "- **Level**: Intermediate\n",
    "- **Time to complete**: 15 minutes\n",
    "- **Prerequisites**: You must have an API key from an active OpenAI account as this tutorial is using the gpt-3.5-turbo model by OpenAI.\n",
    "- **Components Used**: `PromptBuilder`, `GPTGenerator`, `OutputParser` (Custom component)\n",
    "- **Goal**: After completing this tutorial, you will have built a system that extracts unstructured data, puts it in a JSON schema, and automatically corrects errors in the JSON output from a large language model (LLM) to make sure it follows the specified structure.\n",
    "\n",
    "> This tutorial uses Haystack 2.0 Beta. To learn more, see [Haystack 2.0 Documentation](https://docs.haystack.deepset.ai/v2.0/docs).\n",
    "\n",
    "## Overview\n",
    "This tutorial demonstrates how to use Haystack 2.0's advanced [looping pipelines](https://docs.haystack.deepset.ai/v2.0/docs/pipelines#loops) with LLMs for more dynamic and flexible data processing. You'll learn how to extract structured data from unstructured data using an LLM, and to validate the generated output against a predefined schema.\n",
    "\n",
    "This tutorial uses gpt-3.5-turbo to change unstructured passages into JSON outputs that follow the [Pydantic](https://github.com/pydantic/pydantic) schema. It uses a custom OutputParser component to validate the JSON and loop back to make corrections, if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmiAHh1oGsKI"
   },
   "source": [
    "## Preparing the Colab Environment\n",
    "\n",
    "Enable the debug mode of logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vor9IHuNRvEh"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"canals.pipeline.pipeline\").setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljbWiyJkKiPw"
   },
   "source": [
    "## Installing Dependencies\n",
    "Install Haystack 2.0 Beta and [colorama](https://pypi.org/project/colorama/) with pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kcc1AlLQd_jI",
    "outputId": "93374f28-912f-4a21-ca26-cdc416aaf000"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pip install haystack-ai\n",
    "pip install colorama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTA5fdvCLMKD"
   },
   "source": [
    "### Enabling Telemetry\n",
    "\n",
    "Enable telemetry to let us know you're using this tutorial. (You can always opt out by commenting out this line). For details, see [Telemetry](https://docs.haystack.deepset.ai/docs/telemetry)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Apay3QSQLKdM"
   },
   "outputs": [],
   "source": [
    "from haystack.telemetry import tutorial_running\n",
    "\n",
    "tutorial_running(29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvNhg0bP7kfg"
   },
   "source": [
    "## Creating a Custom Component: OutputParser\n",
    "\n",
    "OutputParser is a custom component that validates if the JSON the LLM generates complies with the pydantic schema. If it doesn't, OutputParser sends back an error message along with the incorrect JSON object to get it fixed in the next loop.\n",
    "\n",
    "For more details, see [Creating Custom Components](https://docs.haystack.deepset.ai/v2.0/docs/custom-components)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yr6D8RN2d7Vy"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pydantic\n",
    "from pydantic import ValidationError\n",
    "from typing import Optional, List\n",
    "from colorama import Fore\n",
    "from haystack import component\n",
    "\n",
    "# Define the component input parameters\n",
    "@component\n",
    "class OutputParser:\n",
    "    def __init__(self, pydantic_model: pydantic.BaseModel):\n",
    "        self.pydantic_model = pydantic_model\n",
    "        self.iteration_counter = 0\n",
    "\n",
    "    # Define the component output\n",
    "    @component.output_types(valid_replies=List[str], invalid_replies=Optional[List[str]], error_message=Optional[str])\n",
    "    def run(self, replies: List[str]):\n",
    "\n",
    "        self.iteration_counter += 1\n",
    "\n",
    "        ##### CREATE AN INVALID REPLY (FOR DEMO PURPOSES) #####\n",
    "        # Simulate a corrupt JSON randomly by adding extra brackets\n",
    "        # In a working application, you won't need this section\n",
    "        if random.randint(0, 100) < 30:\n",
    "            replies[0] = \"{{\" + replies[0]\n",
    "        #######################################################\n",
    "\n",
    "        try:\n",
    "            output_dict = json.loads(replies[0])\n",
    "            self.pydantic_model.parse_obj(output_dict)\n",
    "            print(\n",
    "                Fore.GREEN\n",
    "                + f\"OutputParser at Iteration {self.iteration_counter}: Valid JSON from LLM - No need for looping: {replies[0]}\"\n",
    "            )\n",
    "            return {\"valid_replies\": replies}\n",
    "\n",
    "        except (ValueError, ValidationError) as e:\n",
    "            print(\n",
    "                Fore.RED\n",
    "                + f\"OutputParser at Iteration {self.iteration_counter}: Invalid JSON from LLM - Let's try again.\\n\"\n",
    "                f\"Output from LLM:\\n {replies[0]} \\n\"\n",
    "                f\"Error from OutputParser: {e}\"\n",
    "            )\n",
    "            return {\"invalid_replies\": replies, \"error_message\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rbnns33O5Fiy"
   },
   "source": [
    "## Defining a Schema to Parse the JSON Object\n",
    "\n",
    "Define a simple schema for the data you want to extract from a text passsage using the LLM. The output of the LLM should always be compliant with this `json_schema`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwKrDOOGdaAz"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class City(BaseModel):\n",
    "    name: str\n",
    "    country: str\n",
    "    population: int\n",
    "\n",
    "\n",
    "class CitiesData(BaseModel):\n",
    "    cities: List[City]\n",
    "\n",
    "\n",
    "json_schema = CitiesData.schema_json(indent=2)\n",
    "output_parser = OutputParser(pydantic_model=CitiesData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcIWKjW4k42r"
   },
   "source": [
    "## Creating the Prompt\n",
    "\n",
    "Write instructions for the LLM for converting a passage into a JSON format. Ensure the instructions explain how to identify and correct errors if the JSON doesn't match the required schema. Once you create the prompt, initialize PromptBuilder to use it.  \n",
    "\n",
    "For information about Jinja2 template and PromptBuilder, see [PromptBuilder](https://docs.haystack.deepset.ai/v2.0/docs/promptbuilder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohPpNALjdVKt"
   },
   "outputs": [],
   "source": [
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Create a JSON object from the information present in this passage: {{passage}}.\n",
    "Only use information that is present in the passage. Follow this JSON schema, but only return the actual instances without any additional schema definition:\n",
    "{{schema}}\n",
    "Make sure your response is a dict and not a list.\n",
    "{% if invalid_replies and error_message %}\n",
    "  You already created the following output in a previous attempt: {{invalid_replies}}\n",
    "  However, this doesn't comply with the format requirements from above and triggered this Python exception: {{error_message}}\n",
    "  Correct the output and try again. Just return the corrected output without any extra explanations.\n",
    "{% endif %}\n",
    "\"\"\"\n",
    "prompt_builder = PromptBuilder(template=prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KM9-Zq2FL7Nn"
   },
   "source": [
    "## Initalizing the Generator\n",
    "\n",
    "[GPTGenerator](https://docs.haystack.deepset.ai/v2.0/docs/gptgenerator) generates text using OpenAI's gpt-3.5-turbo model by default. Provide an API key and a model name to the Generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z4cQteIgunUR",
    "outputId": "945fe8fc-f540-41be-dc7f-269a3dc8b073"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "from haystack.components.generators import GPTGenerator\n",
    "\n",
    "llm_api_key = os.getenv(\"OPENAI_API_KEY\", getpass(\"Enter OpenAI API key:\"))\n",
    "generator = GPTGenerator(api_key=llm_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbotIOgXHkC5"
   },
   "source": [
    "## Building the Pipeline\n",
    "\n",
    "Add all components to your pipeline and connect them. Add connections from `output_parser` back to the `prompt_builder` for cases where the produced JSON doesn't comply with the JSON schema. Set `max_loops_allowed` to avoid infinite looping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eFglN9YEv-1W"
   },
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "\n",
    "pipeline = Pipeline(max_loops_allowed=5)\n",
    "\n",
    "# Add components to your pipeline\n",
    "pipeline.add_component(instance=prompt_builder, name=\"prompt_builder\")\n",
    "pipeline.add_component(instance=generator, name=\"llm\")\n",
    "pipeline.add_component(instance=output_parser, name=\"output_parser\")\n",
    "\n",
    "# Now, connect the components to each other\n",
    "pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "pipeline.connect(\"llm\", \"output_parser\")\n",
    "# If a component has more than one output or input, explicitly specify the connections:\n",
    "pipeline.connect(\"output_parser.invalid_replies\", \"prompt_builder.invalid_replies\")\n",
    "pipeline.connect(\"output_parser.error_message\", \"prompt_builder.error_message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UKW5wtIIT7w"
   },
   "source": [
    "### Visualize the Pipeline\n",
    "\n",
    "Draw the pipeline with the `draw()` method to confirm the connections are correct. You can find the diagram in the Files section of this Collab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZJg6YHId300"
   },
   "outputs": [],
   "source": [
    "pipeline.draw(\"auto-correct-pipeline.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kV_kexTjImpo"
   },
   "source": [
    "## Testing the Pipeline\n",
    "\n",
    "Run the pipeline with an example passage that you want to convert into a JSON format and the correct `json_schema`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWxmPgADS_Fa"
   },
   "source": [
    "> If you encounter `PipelineMaxLoops: Maximum loops count (5) exceeded for component 'prompt_builder'.` error, run the pipeline again. You're getting this error because `OutputParser` randomly corrupts the JSON, so it may happen that 5 loops are not enough to get the correct output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yIoMedb6eKia",
    "outputId": "611400f3-b6a3-4c50-b0f7-1c4d955df6b0"
   },
   "outputs": [],
   "source": [
    "passage = \"Berlin is the capital of Germany. It has a population of 3,850,809\"\n",
    "result = pipeline.run({\"prompt_builder\": {\"passage\": passage, \"schema\": json_schema}})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWPawSjgSJAM"
   },
   "source": [
    "### Print the Correct JSON\n",
    "If you didn't get any error, you can now print the corrected JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BVO47gXQQnDC",
    "outputId": "fe393e95-4323-487e-c168-a446267af411"
   },
   "outputs": [],
   "source": [
    "valid_reply = result[\"output_parser\"][\"valid_replies\"][0]\n",
    "valid_json = json.loads(valid_reply)\n",
    "print(valid_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Egz_4h2vI_QL"
   },
   "source": [
    "🎉 Congratulations! You've built a system that generates structured JSON out of unstructured text passages, and auto-corrects it by using the looping functionality of Haystack pipelines."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
