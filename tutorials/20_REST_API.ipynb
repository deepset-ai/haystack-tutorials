{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haystack with REST API\n",
    "\n",
    "- **Level**: Intermediate\n",
    "- **Time to complete**: 30 minutes\n",
    "- **Prerequisites**: N/A\n",
    "- **Nodes Used**: `ElasticsearchDocumentStore`, `EmbeddingRetriever`\n",
    "- **Goal**: After completing this tutorial, you will have learned how you can interact with Haystack through REST API.\n",
    "\n",
    "This tutorial teaches you how to create your production-ready document search `pipeline.yml` and interact with Haystack through REST API. \n",
    "\n",
    "First, we are going to set up the environment to run the same question answering pipeline in [Explore the World Demo](https://haystack-demo.deepset.ai/), then create a new pipeline for the new document search system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Environment\n",
    "\n",
    "For this tutorial, we are going to need Elasticsearch and Haystack API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Docker\n",
    "\n",
    "Start up Haystack API via Docker Compose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Update/install Docker and Docker Compose, then launch Docker**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "apt-get update && apt-get install docker && apt-get install docker-compose\n",
    "service docker start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Clone Haystack repository**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "git clone https://github.com/deepset-ai/haystack.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Launch Elasticsearch**\n",
    "\n",
    "Launching Elasticsearch takes some time, so, be sure to have a `healthy` Elasticsearch container before continue. You can check the health through `docker ps` command. \n",
    "\n",
    "Check the other Elasticsearch initializing methods [here](https://docs.haystack.deepset.ai/docs/document_store#initialization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd haystack\n",
    "docker-compose elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  **Launch Haystack API**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When Elasticsearch container is ready, start the Haystack API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "docker-compose haystack-api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Docker\n",
    "\n",
    "If you prefer to not use Docker with your Haystack API, you can start the REST API server and supporting Haystack pipeline by running the gunicorn server manually with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pip install --upgrade pip\n",
    "pip install 'farm-haystack[all]' ## or 'all-gpu' for the GPU-enabled dependencies\n",
    "pip install -e rest_api/\n",
    "\n",
    "brew install xpdf  ## required for `PDFToTextConverter` \n",
    "\n",
    "gunicorn rest_api.application:app -b 0.0.0.0:8000 -k uvicorn.workers.UvicornWorker -t 300 ## start the gunicorn server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find more information about installing Haystack at [the installation guide](https://docs.haystack.deepset.ai/docs/installation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "When setting up is done, you should notice that: \n",
    "* Haystack API: listens on port 8000\n",
    "* DocumentStore (Elasticsearch): listens on port 9200\n",
    "\n",
    "Test whether everything is okay by going to Swagger documentation for the Haystack REST API on [`http://127.0.0.1:8000/docs`](http://127.0.0.1:8000/docs) and trying out `/initialized` endpoint or sending a cURL request as `curl -X GET http://127.0.0.1:8000/initialized`. \n",
    "\n",
    "If everything is alright, you can start asking questions! Wikipedia pages about countries and capital are already indexed to Elasticsearch by the docker image we provided in [`docker-compose.yml`](https://github.com/deepset-ai/haystack/blob/main/docker-compose.yml#L22). To ask questions, you can use `/query` endpoint again via Haystack REST API UI or a cURL request.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X 'POST' \\\n",
    "  'http://127.0.0.1:8000/query' \\\n",
    "  -H 'accept: application/json' \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '{\n",
    "  \"query\": \"What is the capital of Sudan\",\n",
    "  \"params\": {}\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your pipeline\n",
    "\n",
    "Now you know how REST API works, you can start customizing the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Elasticsearch \n",
    "\n",
    "Replace the Docker image with your image or use suitable Elasticsearch image. Use `image: \"docker.elastic.co/elasticsearch/elasticsearch:7.9.2\"` for an empty DocumentStore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Go to your `docker-compose.yml` file\n",
    "* Replace line 22 with `image: \"docker.elastic.co/elasticsearch/elasticsearch:7.9.2\"`\n",
    "* Restart Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new `docker-compose.yml` file should look like this:\n",
    "\n",
    "```yaml\n",
    "...\n",
    "elasticsearch:\n",
    "  image: \"docker.elastic.co/elasticsearch/elasticsearch:7.9.2\"\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New document search pipeline\n",
    "\n",
    "We are going to create a document search pipeline. Create a new file named `document-search.haystack-pipeline.yml` in `/pipeline` folder. Do not forget to update `PIPELINE_YAML_PATH` in `config.py` with the new file name.\n",
    "\n",
    "```python\n",
    "PIPELINE_YAML_PATH = os.getenv(\n",
    "    \"PIPELINE_YAML_PATH\", str((Path(__file__).parent / \"pipeline\" / \"document-search.haystack-pipeline.yml\").absolute())\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using Docker Compose for Haystack API, there are further changes you need to make in `docker-compose.yml`:\n",
    "1. Create `volumes` with the path to the `document-search.haystack-pipeline.yml` file:\n",
    "    ```yaml\n",
    "    ...\n",
    "      haystack-api:\n",
    "        image: \"deepset/haystack:cpu-main\"\n",
    "        volumes:\n",
    "          - /<path_to_haystack>/haystack/rest_api/rest_api/pipeline:/home/user/rest_api/pipeline\n",
    "    ...\n",
    "    ``` \n",
    "2. Update the `PIPELINE_YAML_PATH` value as `/home/user/rest_api/pipeline/document-search.haystack-pipeline.yml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document search pipeline only requires a Retriever. Therefore, it is going to be enough for our query pipeline if we declare a DocumentStore and Retriever in `document-search.haystack-pipeline.yml`. \n",
    "\n",
    "Learn more about YAML files in [YAML File Definitions](https://docs.haystack.deepset.ai/docs/pipelines#yaml-file-definitions). \n",
    "\n",
    "```yaml\n",
    "...\n",
    "components:\n",
    "  - name: DocumentStore\n",
    "    type: ElasticsearchDocumentStore\n",
    "    params:\n",
    "      host: localhost\n",
    "      embedding_dim: 768\n",
    "  - name: Retriever\n",
    "    type: EmbeddingRetriever\n",
    "    params:\n",
    "      document_store: DocumentStore\n",
    "      embedding_model: sentence-transformers/multi-qa-mpnet-base-dot-v1 \n",
    "      model_format: sentence_transformers\n",
    "      top_k: 5 \n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the query pipeline with a Retriever should look like this:\n",
    "\n",
    "```yaml\n",
    "...\n",
    "pipelines:\n",
    "  - name: query\n",
    "    nodes:\n",
    "      - name: Retriever\n",
    "        inputs: [Query]\n",
    "...\n",
    "```\n",
    "Be sure to have the same `name` with `QUERY_PIPELINE_NAME` variable in `config.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing pipeline\n",
    "\n",
    "You can use REST API to index your files to your document store. This requires an indexing pipeline. Add the indexing pipeline to `document-search.haystack-pipeline.yml`, then, you can use `/file-upload` endpoint to upload your files to Elasticsearch. \n",
    "\n",
    "Download the same demo files [here](https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/article_txt_countries_and_capitals.zip) and upload them using cURL. Check [this](https://docs.haystack.deepset.ai/docs/rest_api#indexing-documents-in-the-haystack-rest-api-document-store) documentation page for more detail about file indexing.\n",
    "\n",
    "<aside>\n",
    "⚠️ If you want to index your files directly to Elasticsearch through script, be sure to provide the same indexing pipeline with your `document-search.haystack-pipeline.yml` file for consistency between indexed files.\n",
    "\n",
    "</aside>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indexing pipeline should be as follows:\n",
    "```yaml\n",
    "...\n",
    "components:\n",
    "    ...\n",
    "  - name: FileTypeClassifier \n",
    "    type: FileTypeClassifier\n",
    "  - name: TextConverter \n",
    "    type: TextConverter\n",
    "  - name: PDFConverter \n",
    "    type: PDFToTextConverter\n",
    "  - name: Preprocessor \n",
    "    type: PreProcessor\n",
    "    params:\n",
    "      split_by: word \n",
    "      split_length: 768 \n",
    "      split_overlap: 50 \n",
    "      split_respect_sentence_boundary: True \n",
    "\n",
    "pipelines:\n",
    "    ...\n",
    "    - name: indexing\n",
    "    nodes:\n",
    "      - name: FileTypeClassifier\n",
    "        inputs: [File]\n",
    "      - name: TextConverter\n",
    "        inputs: [FileTypeClassifier.output_1] \n",
    "      - name: PDFConverter\n",
    "        inputs: [FileTypeClassifier.output_2]\n",
    "      - name: Preprocessor\n",
    "        inputs: [TextConverter, PDFConverter]\n",
    "      - name: Retriever\n",
    "        inputs: [Preprocessor]\n",
    "      - name: DocumentStore\n",
    "        inputs: [Retriever]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "After merging query and the indexing pipelines, the final `document-search.haystack-pipeline.yml` file should look like this:\n",
    "\n",
    "```yaml\n",
    "version: 'ignore'\n",
    "\n",
    "components:\n",
    "  - name: DocumentStore\n",
    "    type: ElasticsearchDocumentStore \n",
    "      host: localhost\n",
    "      embedding_dim: 768\n",
    "  - name: Retriever \n",
    "    type: EmbeddingRetriever\n",
    "    params:\n",
    "      document_store: DocumentStore\n",
    "      embedding_model: sentence-transformers/multi-qa-mpnet-base-dot-v1\n",
    "      model_format: sentence_transformers\n",
    "      top_k: 5\n",
    "  - name: FileTypeClassifier\n",
    "    type: FileTypeClassifier\n",
    "  - name: TextConverter \n",
    "    type: TextConverter\n",
    "  - name: PDFConverter\n",
    "    type: PDFToTextConverter\n",
    "  - name: Preprocessor\n",
    "    type: PreProcessor\n",
    "    params:\n",
    "      split_by: word \n",
    "      split_length: 768 \n",
    "      split_overlap: 50 \n",
    "      split_respect_sentence_boundary: True \n",
    "\n",
    "pipelines:\n",
    "  - name: query\n",
    "    nodes:\n",
    "      - name: Retriever\n",
    "        inputs: [Query]\n",
    "  - name: indexing\n",
    "    nodes:\n",
    "      - name: FileTypeClassifier\n",
    "        inputs: [File]\n",
    "      - name: TextConverter\n",
    "        inputs: [FileTypeClassifier.output_1]\n",
    "      - name: PDFConverter\n",
    "        inputs: [FileTypeClassifier.output_2]\n",
    "      - name: Preprocessor\n",
    "        inputs: [TextConverter, PDFConverter]\n",
    "      - name: Retriever\n",
    "        inputs: [Preprocessor]\n",
    "      - name: DocumentStore\n",
    "        inputs: [Retriever]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you restart the Haystack API, REST API is going to load the new pipeline and the pipeline will be ready to use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voilà! Make a new query!\n",
    "\n",
    "This query should retrieve documents about _\"climate in Scandinavia\"_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X 'POST' \\\n",
    "  'http://localhost:8000/query' \\\n",
    "  -H 'accept: application/json' \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '{\n",
    "  \"query\": \"climate in Scandinavia\",\n",
    "  \"params\": {}\n",
    "}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
